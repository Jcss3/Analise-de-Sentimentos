{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e ajuste dos Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o caminho dos dados\n",
    "data_company_path = \"dados/Company.csv\"\n",
    "data_tweet_path = \"dados/Tweet.csv\"\n",
    "data_company_tweet_path = \"dados/Company_Tweet.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler e colocar em um dataframe\n",
    "data_company = pd.read_csv(data_company_path)\n",
    "data_tweet = pd.read_csv(data_tweet_path)\n",
    "data_company_tweet = pd.read_csv(data_company_tweet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id ticker_symbol\n",
      "0  550803612197457920          AAPL\n",
      "1  550803610825928706          AAPL\n",
      "2  550803225113157632          AAPL\n",
      "3  550802957370159104          AAPL\n",
      "4  550802855129382912          AAPL\n",
      "(4336445, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data_company_tweet.head())\n",
    "print(data_company_tweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker_symbol company_name\n",
      "0          AAPL        apple\n",
      "1          GOOG   Google Inc\n",
      "2         GOOGL   Google Inc\n",
      "3          AMZN   Amazon.com\n",
      "4          TSLA    Tesla Inc\n",
      "5          MSFT    Microsoft\n",
      "(6, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data_company)\n",
    "print(data_company.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id           writer   post_date  \\\n",
      "0  550441509175443456  VisualStockRSRC  1420070457   \n",
      "1  550441672312512512      KeralaGuy77  1420070496   \n",
      "2  550441732014223360      DozenStocks  1420070510   \n",
      "3  550442977802207232     ShowDreamCar  1420070807   \n",
      "4  550443807834402816     i_Know_First  1420071005   \n",
      "\n",
      "                                                body  comment_num  \\\n",
      "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
      "1  Insanity of today weirdo massive selling. $aap...            0   \n",
      "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
      "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
      "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
      "\n",
      "   retweet_num  like_num  \n",
      "0            0         1  \n",
      "1            0         0  \n",
      "2            0         0  \n",
      "3            0         1  \n",
      "4            0         1  \n",
      "(3717964, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data_tweet.head())\n",
    "print(data_tweet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550803612197457920</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550803610825928706</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550803225113157632</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550802957370159104</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550802855129382912</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id company_name\n",
       "0  550803612197457920        apple\n",
       "1  550803610825928706        apple\n",
       "2  550803225113157632        apple\n",
       "3  550802957370159104        apple\n",
       "4  550802855129382912        apple"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_merge1 = pd.merge(data_company_tweet,data_company, on='ticker_symbol')\n",
    "dados_merge1 = dados_merge1.drop(columns=['ticker_symbol'])\n",
    "dados_merge1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Inc</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name      writer   post_date  \\\n",
       "0        apple  SentiQuant  1420156789   \n",
       "1   Amazon.com  SentiQuant  1420156789   \n",
       "2        apple  SentiQuant  1420156788   \n",
       "3   Google Inc  SentiQuant  1420156788   \n",
       "4   Amazon.com  SentiQuant  1420156788   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "1  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "2  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "3  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "4  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "\n",
       "   retweet_num  like_num  \n",
       "0            0         1  \n",
       "1            0         1  \n",
       "2            0         1  \n",
       "3            0         1  \n",
       "4            0         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_tweet_company = pd.merge(dados_merge1,data_tweet,on='tweet_id')\n",
    "dados_tweet_company = dados_tweet_company.drop(columns=['tweet_id'])\n",
    "dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados_tweet_company = dados_tweet_company.iloc[:500000]\n",
    "#dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4336445, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_tweet_company.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar Tempo (Data do Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1420156789"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_tweet_company.post_date[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-01-01 20:59:49'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_epoch = dados_tweet_company.post_date[0]\n",
    "ts = datetime.datetime.fromtimestamp(ts_epoch).strftime('%Y-%m-%d %H:%M:%S')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Inc</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name      writer   post_date  \\\n",
       "0        apple  SentiQuant  1420156789   \n",
       "1   Amazon.com  SentiQuant  1420156789   \n",
       "2        apple  SentiQuant  1420156788   \n",
       "3   Google Inc  SentiQuant  1420156788   \n",
       "4   Amazon.com  SentiQuant  1420156788   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "1  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "2  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "3  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "4  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "\n",
       "   retweet_num  like_num                 Date  \n",
       "0            0         1  2015-01-01 20:59:49  \n",
       "1            0         1  2015-01-01 20:59:49  \n",
       "2            0         1  2015-01-01 20:59:48  \n",
       "3            0         1  2015-01-01 20:59:48  \n",
       "4            0         1  2015-01-01 20:59:48  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ajustar_tempo(row):\n",
    "    ts_epoch = row['post_date']\n",
    "    ts = datetime.datetime.fromtimestamp(ts_epoch).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return ts  \n",
    "new_date = dados_tweet_company.apply(ajustar_tempo,axis=1)\n",
    "dados_tweet_company['Date'] = list(new_date)\n",
    "dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4336445 entries, 0 to 4336444\n",
      "Data columns (total 8 columns):\n",
      "company_name    object\n",
      "writer          object\n",
      "post_date       int64\n",
      "body            object\n",
      "comment_num     int64\n",
      "retweet_num     int64\n",
      "like_num        int64\n",
      "Date            object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 297.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dados_tweet_company.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo Caracteres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN $T $IGN $SPY $FB $UGAZ #sentiquant 20150101 19:00:08:298\n",
      "Our Penny Stock Picks Gained Over 968% In the Past 5 Weeks! Get our next pick early: http://tinyurl.com/p46mnk2 $TRX $AAPL $GOOG\n"
     ]
    }
   ],
   "source": [
    "sentenca = dados_tweet_company.body[0]\n",
    "print(sentenca)\n",
    "\n",
    "sentenca_2 = dados_tweet_company.body[100]\n",
    "print(sentenca_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>Date</th>\n",
       "      <th>Processed_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Inc</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name      writer   post_date  \\\n",
       "0        apple  SentiQuant  1420156789   \n",
       "1   Amazon.com  SentiQuant  1420156789   \n",
       "2        apple  SentiQuant  1420156788   \n",
       "3   Google Inc  SentiQuant  1420156788   \n",
       "4   Amazon.com  SentiQuant  1420156788   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "1  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "2  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "3  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "4  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "\n",
       "   retweet_num  like_num                 Date        Processed_Tweet  \n",
       "0            0         1  2015-01-01 20:59:49  20150101 19:00:08:298  \n",
       "1            0         1  2015-01-01 20:59:49  20150101 19:00:08:298  \n",
       "2            0         1  2015-01-01 20:59:48  20150101 19:00:04:526  \n",
       "3            0         1  2015-01-01 20:59:48  20150101 19:00:04:526  \n",
       "4            0         1  2015-01-01 20:59:48  20150101 19:00:04:526  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_all(texto):\n",
    "    palavras_especiais = [word for word in texto.split(' ') if word.startswith(('#','$','@'))]\n",
    "    #print(palavras_especiais)\n",
    "    sentenca = ' '.join(x for x in texto.split(' ') if x not in palavras_especiais)\n",
    "    return sentenca\n",
    "\n",
    "new_strings = dados_tweet_company.body.apply(replace_all)\n",
    "dados_tweet_company['Processed_Tweet'] = list(new_strings)\n",
    "dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20150101 19:00:08:298\n",
      "Our Penny Stock Picks Gained Over 968% In the Past 5 Weeks! Get our next pick early: http://tinyurl.com/p46mnk2\n"
     ]
    }
   ],
   "source": [
    "sentenca = dados_tweet_company.Processed_Tweet[0]\n",
    "print(sentenca)\n",
    "\n",
    "sentenca_2 = dados_tweet_company.Processed_Tweet[100]\n",
    "print(sentenca_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados_tweet_company['Date'] = pd.to_datetime(dados_tweet_company['Date'])\n",
    "#dados_tweet_company = dados_tweet_company[dados_tweet_company['Date'].dt.year == 2019]\n",
    "#dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados_tweet_company = dados_tweet_company[dados_tweet_company.company_name == 'Microsoft']\n",
    "#print(dados_tweet_company.shape)\n",
    "#dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando Labels para os Tweets \n",
    "* Positivo = 1 or pos\n",
    "* Neutro = 0 or neu\n",
    "* Negativo = -1 or neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.959, 'pos': 0.041, 'compound': 0.2023}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "sid.polarity_scores(dados_tweet_company.body[1541910])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4336445, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_tweet_company.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>Date</th>\n",
       "      <th>Processed_Tweet</th>\n",
       "      <th>vader_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Inc</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name      writer   post_date  \\\n",
       "0        apple  SentiQuant  1420156789   \n",
       "1   Amazon.com  SentiQuant  1420156789   \n",
       "2        apple  SentiQuant  1420156788   \n",
       "3   Google Inc  SentiQuant  1420156788   \n",
       "4   Amazon.com  SentiQuant  1420156788   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "1  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "2  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "3  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "4  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "\n",
       "   retweet_num  like_num                 Date        Processed_Tweet  \\\n",
       "0            0         1  2015-01-01 20:59:49  20150101 19:00:08:298   \n",
       "1            0         1  2015-01-01 20:59:49  20150101 19:00:08:298   \n",
       "2            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "3            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "4            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "\n",
       "                                        vader_scores  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_tweet_company['vader_scores']  = None\n",
    "dados_tweet_company['vader_scores'] = dados_tweet_company.Processed_Tweet.apply(lambda tweet : sid.polarity_scores(tweet))\n",
    "dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>Date</th>\n",
       "      <th>Processed_Tweet</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Inc</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name      writer   post_date  \\\n",
       "0        apple  SentiQuant  1420156789   \n",
       "1   Amazon.com  SentiQuant  1420156789   \n",
       "2        apple  SentiQuant  1420156788   \n",
       "3   Google Inc  SentiQuant  1420156788   \n",
       "4   Amazon.com  SentiQuant  1420156788   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "1  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "2  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "3  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "4  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "\n",
       "   retweet_num  like_num                 Date        Processed_Tweet  \\\n",
       "0            0         1  2015-01-01 20:59:49  20150101 19:00:08:298   \n",
       "1            0         1  2015-01-01 20:59:49  20150101 19:00:08:298   \n",
       "2            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "3            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "4            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "\n",
       "                                        vader_scores  compound  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separar os valores do compound - vamos uas-lo para determinar os lbels dos tweets pos/beg\n",
    "dados_tweet_company['compound']  = dados_tweet_company['vader_scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>Date</th>\n",
       "      <th>Processed_Tweet</th>\n",
       "      <th>vader_scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156789</td>\n",
       "      <td>#TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:49</td>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Inc</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>SentiQuant</td>\n",
       "      <td>1420156788</td>\n",
       "      <td>#SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 20:59:48</td>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name      writer   post_date  \\\n",
       "0        apple  SentiQuant  1420156789   \n",
       "1   Amazon.com  SentiQuant  1420156789   \n",
       "2        apple  SentiQuant  1420156788   \n",
       "3   Google Inc  SentiQuant  1420156788   \n",
       "4   Amazon.com  SentiQuant  1420156788   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "1  #TOPTICKERTWEETS $AAPL $IMRS $BABA $EBAY $AMZN...            0   \n",
       "2  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "3  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "4  #SENTISHIFTUP $K $FB $GOOGL $GS $GOLD $T $AAPL...            0   \n",
       "\n",
       "   retweet_num  like_num                 Date        Processed_Tweet  \\\n",
       "0            0         1  2015-01-01 20:59:49  20150101 19:00:08:298   \n",
       "1            0         1  2015-01-01 20:59:49  20150101 19:00:08:298   \n",
       "2            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "3            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "4            0         1  2015-01-01 20:59:48  20150101 19:00:04:526   \n",
       "\n",
       "                                        vader_scores  compound label  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0   neu  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0   neu  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0   neu  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0   neu  \n",
       "4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...       0.0   neu  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definindo os labels usando o compund value como referenecia\n",
    "def labels(value):\n",
    "    if value == 0:\n",
    "        return 'neu'\n",
    "    elif value > 0:\n",
    "        return 'pos'\n",
    "    elif value < 0:\n",
    "        return 'neg'\n",
    "    \n",
    "dados_tweet_company['label']  = dados_tweet_company['compound'].apply(lambda value: labels(value))\n",
    "dados_tweet_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    1883920\n",
       "pos    1703413\n",
       "neg     749112\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_tweet_company.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados para ML\n",
    "* Processed_Tweet - feature\n",
    "* Label - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed_Tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20150101 19:00:08:298</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20150101 19:00:04:526</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Processed_Tweet label\n",
       "0  20150101 19:00:08:298   neu\n",
       "1  20150101 19:00:08:298   neu\n",
       "2  20150101 19:00:04:526   neu\n",
       "3  20150101 19:00:04:526   neu\n",
       "4  20150101 19:00:04:526   neu"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separando os valores para a machine learning\n",
    "dados = dados_tweet_company[['Processed_Tweet','label']]\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    1883920\n",
       "pos    1703413\n",
       "neg     749112\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho POS: 1703413\n",
      "Tamanho NEU: 1883920\n",
      "Tamanho NEG: 749112\n",
      "####################################################################################################\n",
      "Tamanhos:  [1703413, 1883920, 749112]\n",
      "####################################################################################################\n",
      "749112\n"
     ]
    }
   ],
   "source": [
    "# filtrar dados por fase\n",
    "dataset_pos = dados[dados['label']=='pos']\n",
    "dataset_neu = dados[dados['label']=='neu']\n",
    "dataset_neg = dados[dados['label']=='neg']\n",
    "\n",
    "print(f'Tamanho POS: {len(dataset_pos)}')\n",
    "print(f'Tamanho NEU: {len(dataset_neu)}')\n",
    "print(f'Tamanho NEG: {len(dataset_neg)}')\n",
    "\n",
    "print('#'*100)\n",
    "dataset_tamanhos = [len(dataset_pos),len(dataset_neu),len(dataset_neg)]\n",
    "print('Tamanhos: ',dataset_tamanhos)\n",
    "print('#'*100)\n",
    "\n",
    "tamanho_min = min(dataset_tamanhos)\n",
    "print(tamanho_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a = dataset_pos.iloc[:tamanho_min-1].copy()\n",
    "data_b = dataset_neu.iloc[:tamanho_min-1].copy()\n",
    "data_c = dataset_neg.iloc[:tamanho_min-1].copy()\n",
    "\n",
    "frames = [data_a, data_b,data_c]\n",
    "\n",
    "df_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2247333, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed_Tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An store line in Sapporo Japan for the \"Lucky ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>- Will Give Second entry opportunity? - https:...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Will Give Second entry opportunity? http://tra...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We will book gains in half dozen picks tomorro...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"@CNBC: This is Wall Street's top pick in 2015...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Processed_Tweet label\n",
       "6   An store line in Sapporo Japan for the \"Lucky ...   pos\n",
       "7   - Will Give Second entry opportunity? - https:...   pos\n",
       "8   Will Give Second entry opportunity? http://tra...   pos\n",
       "9   We will book gains in half dozen picks tomorro...   pos\n",
       "16  \"@CNBC: This is Wall Street's top pick in 2015...   pos"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_data.shape)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando conjuntos de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetVariables_train, datasetVariables_test, datasetTarget_train, datasetTarget_test = train_test_split(df_data['Processed_Tweet'], df_data['label'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorizando Tweets\n",
    "* Tokenizer - Tensorflow Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646280\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(datasetVariables_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding Vetores \n",
    "* Tamanho max dos vetores = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de treinamento:  \n",
      " [[     0      0      0 ...     19     15 112004]\n",
      " [     0      0      0 ...     19     15 195539]\n",
      " [     0      0      0 ...    137   6495    450]\n",
      " ...\n",
      " [     0      0      0 ...    126    278     61]\n",
      " [     0      0      0 ...     83     41     91]\n",
      " [     0      0      0 ... 195545     61    116]]\n",
      "Conjunto de teste:  \n",
      " [[     0      0      0 ...     99   1540    127]\n",
      " [     0      0      0 ...     55     16      1]\n",
      " [     0      0      0 ...     27      6   3746]\n",
      " ...\n",
      " [     0      0      0 ...      1  22855      7]\n",
      " [     0      0      0 ...      5 497845    116]\n",
      " [     0      0      0 ...      5   2713   4983]]\n"
     ]
    }
   ],
   "source": [
    "# Transformar as sentencas dos dados de treinamento e teste para sequencias numericas. ex [[1,2,6],[65,952,15,65],[1,2]]\n",
    "train_data_sentences = tokenizer.texts_to_sequences(datasetVariables_train)\n",
    "test_data_sentences = tokenizer.texts_to_sequences(datasetVariables_test)\n",
    "\n",
    "# normalizar o tamnho das sequencias usando padding. ex [[0,1,2,6],[65,952,15,65],[0,0,1,2]]\n",
    "train_padded = pad_sequences(train_data_sentences, maxlen=300)\n",
    "test_padded = pad_sequences(test_data_sentences, maxlen=300)\n",
    "\n",
    "print(\"Conjunto de treinamento: \",\"\\n\",train_padded[0:19])\n",
    "print(\"Conjunto de teste: \",\"\\n\",test_padded[0:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298216     neu\n",
       "452630     neu\n",
       "149558     neg\n",
       "915791     pos\n",
       "2828417    neg\n",
       "1089875    neu\n",
       "584643     pos\n",
       "394869     neu\n",
       "1748568    pos\n",
       "1943215    neg\n",
       "1786346    pos\n",
       "976544     neu\n",
       "2654352    neg\n",
       "915599     pos\n",
       "1329220    pos\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetTarget_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasetTarget_train = to_categorical(np.array(datasetTarget_train))\n",
    "#datasetTarget_test = to_categorical(np.array(datasetTarget_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning \n",
    "* Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=50)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first ML model\n",
    "model_randomForest = RandomForestClassifier(random_state=50,criterion='gini')\n",
    "model_randomForest.fit(train_padded,datasetTarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC TRAINING:0.999853889818312\n",
      "ACC TEST:0.7652261265877404\n"
     ]
    }
   ],
   "source": [
    "predicaoTrain = model_randomForest.predict(train_padded)\n",
    "predicaoTest = model_randomForest.predict(test_padded)\n",
    "\n",
    "print(\"ACC TRAINING:\" + str(accuracy_score(datasetTarget_train, predicaoTrain)))\n",
    "print(\"ACC TEST:\" + str(accuracy_score(datasetTarget_test, predicaoTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.67      0.85      0.75    247017\n",
      "         neu       0.82      0.77      0.80    247437\n",
      "         pos       0.86      0.67      0.76    247166\n",
      "\n",
      "    accuracy                           0.77    741620\n",
      "   macro avg       0.78      0.77      0.77    741620\n",
      "weighted avg       0.78      0.77      0.77    741620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(datasetTarget_test, predicaoTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    247437\n",
       "pos    247166\n",
       "neg    247017\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetTarget_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[191598,  12978,  42861],\n",
       "       [ 18575, 166699,  61892],\n",
       "       [ 23094,  14713, 209210]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(datasetTarget_test, predicaoTest, labels=[\"neu\", \"pos\", \"neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\naive_bayes.py:780: RuntimeWarning: invalid value encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_naiveBayes = MultinomialNB()\n",
    "model_naiveBayes.fit(train_padded,datasetTarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC TRAINING:0.33345929802027346\n",
      "ACC TEST:0.3330775869043445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.33      1.00      0.50    247017\n",
      "         neu       0.00      0.00      0.00    247437\n",
      "         pos       0.00      0.00      0.00    247166\n",
      "\n",
      "    accuracy                           0.33    741620\n",
      "   macro avg       0.11      0.33      0.17    741620\n",
      "weighted avg       0.11      0.33      0.17    741620\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predicaoTrain = model_naiveBayes.predict(train_padded)\n",
    "predicaoTest = model_naiveBayes.predict(test_padded)\n",
    "\n",
    "print(\"ACC TRAINING:\" + str(accuracy_score(datasetTarget_train, predicaoTrain)))\n",
    "print(\"ACC TEST:\" + str(accuracy_score(datasetTarget_test, predicaoTest)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(datasetTarget_test, predicaoTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC TRAINING:0.35654869155011615\n",
      "ACC TEST:0.3597260052317899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.41      0.29      0.34    247017\n",
      "         neu       0.33      0.19      0.24    247437\n",
      "         pos       0.35      0.60      0.44    247166\n",
      "\n",
      "    accuracy                           0.36    741620\n",
      "   macro avg       0.36      0.36      0.34    741620\n",
      "weighted avg       0.36      0.36      0.34    741620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_linear = SGDClassifier()\n",
    "model_linear.fit(train_padded,datasetTarget_train)\n",
    "\n",
    "predicaoTrain = model_linear.predict(train_padded)\n",
    "predicaoTest = model_linear.predict(test_padded)\n",
    "\n",
    "print(\"ACC TRAINING:\" + str(accuracy_score(datasetTarget_train, predicaoTrain)))\n",
    "print(\"ACC TEST:\" + str(accuracy_score(datasetTarget_test, predicaoTest)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(datasetTarget_test, predicaoTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuário\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.37 GiB for an array with shape (1505713, 300) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-7e3aa1bba799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_logisticRegression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_padded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdatasetTarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredicaoTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_logisticRegression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_padded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpredicaoTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_logisticRegression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_padded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 292\u001b[1;33m                                  dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    293\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.37 GiB for an array with shape (1505713, 300) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logisticRegression = LogisticRegression()\n",
    "model_logisticRegression.fit(train_padded,datasetTarget_train)\n",
    "\n",
    "predicaoTrain = model_logisticRegression.predict(train_padded)\n",
    "predicaoTest = model_logisticRegression.predict(test_padded)\n",
    "\n",
    "print(\"ACC TRAINING:\" + str(accuracy_score(datasetTarget_train, predicaoTrain)))\n",
    "print(\"ACC TEST:\" + str(accuracy_score(datasetTarget_test, predicaoTest)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(datasetTarget_test, predicaoTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#import pickle\n",
    "#filename = 'model2_randomForest_80.sav'\n",
    "#pickle.dump(model_v1,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "model_SVM = svm.SVC(gamma='auto')\n",
    "model_SVM.fit(train_padded,datasetTarget_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicaoTrain = model_SVM.predict(train_padded)\n",
    "predicaoTest = model_SVM.predict(test_padded)\n",
    "\n",
    "print(\"ACC TRAINING:\" + str(accuracy_score(datasetTarget_train, predicaoTrain)))\n",
    "print(\"ACC TEST:\" + str(accuracy_score(datasetTarget_test, predicaoTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(datasetTarget_test, predicaoTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(datasetTarget_test, predicaoTest)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = []\n",
    "estimator.append(('SVC', SVC(probability = True)))\n",
    "estimator.append(('RND', RandomForestClassifier()))\n",
    "  \n",
    "# Voting Classifier with hard voting\n",
    "vot_hard = VotingClassifier(estimators = estimator, voting ='hard')\n",
    "vot_hard.fit(X_train, y_train)\n",
    "y_pred = vot_hard.predict(X_test)\n",
    "  \n",
    "# using accuracy_score metric to predict accuracy\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Hard Voting Score % d\" % score)\n",
    "  \n",
    "# Voting Classifier with soft voting\n",
    "vot_soft = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "vot_soft.fit(X_train, y_train)\n",
    "y_pred = vot_soft.predict(X_test)\n",
    "  \n",
    "# using accuracy_score\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Soft Voting Score % d\" % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
